from __future__ import annotations

import random
import time
from typing import Any

from esmerald import Esmerald, Gateway, get
from esmerald.conf import settings
from esmerald.core.caches.memory import InMemoryCache
from esmerald.core.caches.redis import RedisCache
from esmerald.testclient import EsmeraldTestClient
from esmerald.utils.decorators import cache


def test_basic_caching_memory(memory_cache) -> None:
    @cache(backend=memory_cache, ttl=10)
    def slow_function(x: int) -> int:
        return x * 2

    assert slow_function(5) == 10
    assert slow_function(5) == 10  # Should return from cache

    # Ensure function was not called twice
    memory_cache.sync_delete("slow_function:5")
    assert slow_function(5) == 10  # Should recompute


def test_basic_caching_memory_redis(redis_cache) -> None:
    @cache(backend=redis_cache, ttl=10)
    def slow_function(x: int) -> int:
        return x * 2

    assert slow_function(5) == 10
    assert slow_function(5) == 10  # Should return from cache

    # Ensure function was not called twice
    redis_cache.sync_delete("slow_function:5")
    assert slow_function(5) == 10  # Should recompute


async def test_cache_expiry_memory(memory_cache):
    @cache(backend=memory_cache, ttl=1)
    async def short_lived_function() -> str:
        return "cached_value"

    assert await short_lived_function() == "cached_value"
    time.sleep(1.5)  # Wait for expiry
    assert await short_lived_function() == "cached_value"  # Should recompute


async def test_cache_expiry_redis(redis_cache):
    @cache(backend=redis_cache, ttl=1)
    async def short_lived_function() -> str:
        return "cached_value"

    assert await short_lived_function() == "cached_value"
    time.sleep(1.5)  # Wait for expiry
    assert await short_lived_function() == "cached_value"  # Should recompute


async def test_cache_key_generation_memory(memory_cache):
    @cache(backend=memory_cache, ttl=10)
    async def key_test(a: int, b: str) -> str:
        return f"{a}-{b}"

    assert await key_test(1, "hello") == "1-hello"
    assert await key_test(1, "hello") == "1-hello"  # Should return from cache

    # Ensure different arguments create different cache entries
    assert await key_test(2, "hello") == "2-hello"


async def test_cache_key_generation_redis(redis_cache):
    @cache(backend=redis_cache, ttl=10)
    async def key_test(a: int, b: str) -> str:
        return f"{a}-{b}"

    assert await key_test(1, "hello") == "1-hello"
    assert await key_test(1, "hello") == "1-hello"  # Should return from cache

    # Ensure different arguments create different cache entries
    assert await key_test(2, "hello") == "2-hello"


async def test_cache_invalidation_memory(memory_cache):
    """Ensure cache invalidation works properly in memory."""

    @cache(backend=memory_cache, ttl=10)
    async def cached_function(x: int) -> int:
        return x * 3

    assert await cached_function(3) == 9
    memory_cache.sync_delete("cached_function:3")  # Manually clear cache
    assert await cached_function(3) == 9  # Should recompute


async def test_cache_invalidation_redis(redis_cache):
    """Ensure cache invalidation works properly in redis."""

    @cache(backend=redis_cache, ttl=10)
    async def cached_function(x: int) -> int:
        return x * 3

    assert await cached_function(3) == 9
    redis_cache.sync_delete("cached_function:3")  # Manually clear cache
    assert await cached_function(3) == 9  # Should recompute


async def test_cache_backend_failure_memory(caplog):
    """Simulate a cache backend failure and ensure fallback behavior in memory."""

    class BrokenCache(InMemoryCache):
        def sync_get(self, key: str) -> Any | None:
            raise RuntimeError("Simulated backend failure")

    broken_backend = BrokenCache()

    @cache(backend=broken_backend, ttl=10)
    async def unstable_function() -> str:
        return "safe_value"

    with caplog.at_level("ERROR"):
        assert await unstable_function() == "safe_value"  # Should not crash

    assert "Simulated backend failure" in caplog.text  # Ensure error was logged


async def test_cache_backend_failure_redis(caplog):
    """Simulate a cache backend failure and ensure fallback behavior in redis."""

    class BrokenCache(RedisCache):
        def sync_get(self, key: str) -> Any | None:
            raise RuntimeError("Simulated backend failure")

    broken_backend = BrokenCache(redis_url="redis://localhost")

    @cache(backend=broken_backend, ttl=10)
    async def unstable_function() -> str:
        return "safe_value"

    assert await unstable_function() == "safe_value"  # Should not crash


async def test_esmerald_integration_in_memory(memory_cache):
    """Ensure the caching decorator works in an Esmerald application with in-memory caching."""

    @get("/cached/{value}")
    @cache(backend=memory_cache, ttl=1)
    async def endpoint(value: int) -> dict:
        return {"value": value * 2, "random": random.randint(1, 1000)}

    app = Esmerald(routes=[Gateway(handler=endpoint)])

    with EsmeraldTestClient(app) as client:
        response1 = client.get("/cached/10")
        response2 = client.get("/cached/10")

        assert response1.status_code == 200
        assert response2.status_code == 200
        assert response1.json() == response2.json()  # Cached response

        # Compute the exact cache key used
        cache_key = (
            "tests.caches.test_decorator.test_esmerald_integration_in_memory.cached_endpoint:10"
        )
        time.sleep(1)

        # Delete from cache using the correct key
        memory_cache.sync_delete(cache_key)

        # Now fetch again (should be different)
        response3 = client.get("/cached/10")

        assert response3.status_code == 200
        assert response3.json() != response1.json()  # Recomputed value


async def test_esmerald_integration_default():
    """Ensure the caching decorator works in an Esmerald application with default caching."""

    @get("/cached/{value}")
    @cache(ttl=1)
    async def endpoint(value: int) -> dict:
        return {"value": value * 2, "random": random.randint(1, 1000)}

    app = Esmerald(routes=[Gateway(handler=endpoint)])

    with EsmeraldTestClient(app) as client:
        response1 = client.get("/cached/10")
        response2 = client.get("/cached/10")

        assert response1.status_code == 200
        assert response2.status_code == 200
        assert response1.json() == response2.json()  # Cached response

        # Compute the exact cache key used
        cache_key = (
            "tests.caches.test_decorator.test_esmerald_integration_in_memory.cached_endpoint:10"
        )
        time.sleep(1)

        # Delete from cache using the correct key
        settings.cache_backend.sync_delete(cache_key)

        # Now fetch again (should be different)
        response3 = client.get("/cached/10")

        assert response3.status_code == 200
        assert response3.json() != response1.json()  # Recomputed value


async def test_esmerald_integration_in_redis(redis_cache):
    """Ensure the caching decorator works in an Esmerald application in redis."""

    @get("/cached/{value}")
    @cache(backend=redis_cache, ttl=1)
    async def cached_endpoint(value: int) -> dict:
        return {"value": value * 2, "random": random.randint(1, 1000)}

    app = Esmerald(routes=[Gateway(handler=cached_endpoint)])

    with EsmeraldTestClient(app) as client:
        response1 = client.get("/cached/10")
        response2 = client.get("/cached/10")

        assert response1.status_code == 200
        assert response2.status_code == 200
        assert response1.json() == response2.json()  # Cached response

        redis_cache.sync_delete("cached_endpoint:10")
        time.sleep(1)
        response3 = client.get("/cached/10")

        assert response3.status_code == 200
        assert response3.json() != response1.json()  # Recomputed value
